# activity-recognitiom

A convLSTM model and a LRCN model was developed to categorise the action depicted in the video. The models are trained on the dataset UFC-50. 

The Link To the UFC-50 Dataset: https://www.crcv.ucf.edu/data/UCF50.php

colab file link - 

The model is trained using the UFC-50 Dataset. The models are tested using the input videos provided by the user. Any test video can be uploaded to the nitebook and renamed as Test_1 file and can be tested for one of the categories where it belongs. 



ConvLSTM model

A ConvLSTM (Convolutional Long Short-Term Memory) model is a type of neural network architecture that combines the properties of convolutional layers and LSTM (Long Short-Term Memory) layers. It is particularly useful for tasks that involve sequences of data with spatial dependencies, such as video analysis, weather forecasting, and spatiotemporal data analysis. ConvLSTM layers are an extension of the traditional LSTM layers, where the input and hidden states are treated as 2D grids instead of flat vectors.


LRCN model

An LRCN (Long-term Recurrent Convolutional Network) model is a type of neural network architecture that combines convolutional layers (for spatial feature extraction) and recurrent layers (for sequential and temporal modeling). It's commonly used for tasks that involve both image and sequence data, such as video analysis, action recognition, and captioning.
